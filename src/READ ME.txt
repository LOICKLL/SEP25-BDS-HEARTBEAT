# Protocole d'exécution

## Prérequis
- Python 3.10+
- `pip install -r requirements.txt`
- Activation de l'environnement : `.\.venv\Scripts\activate` (Windows)

Etape 1  :  build_mit_beats_csv.py --> Lecture des enregistrement MIT-BIH et création du csv contenant les battements avec leurs label et Filtrages des Leads

	Résumé:lit la base brute MIT-BIH, extrait tous les battements, leur associe un label à 5 classes, 
	découpe chaque battement en fenêtre de 187 points sur chaque lead, ajoute plein de méta-données, 
	et produit un gros CSV prêt pour le Machine Learning : mitbih_187pts_fullmeta.csv.
	En même temps le programme lit le  fichier multi-leads et crée un CSV propre avec uniquement les battements du lead MLII


--Lancer---------->  python src/features/build_mit_beats_csv.py
--On obtient ----->	 data/processed/mitbih_187pts_fullmeta.csv
			 ----->	 data/processed/mitbih_187pts_MLII.csv
			 
Etape 2 : exploration_MIT.py ---> Lecture de mitbih_187pts_fullmeta.csv et dataviz

	Résumé : Charge mitbih_187pts_fullmeta.csv, harmonise quelques champs (sexe, labels) puis réalise une mini-EDA.
	Génère des graphiques (répartition des classes par sexe/âge, heatmap corrélations, signaux moyens par classe, comptage par patient, scatter âge-bpm, distributions âge/genre/leads) et des tests χ² (label~sexe, label~âge).
	Sauvegarde toutes les figures en PNG dans reports/figures/exploration_MIT. 
	
--Lancer----------> python src/visualization/exploration_MIT.py
--On obtient -----> reports/figures/exploration_MIT/repartition_labels_global.png
　　　　　　-----> reports/figures/exploration_MIT/repartition_labels_par_sexe.png
　　　　　　-----> reports/figures/exploration_MIT/repartition_labels_par_age.png
　　　　　　-----> reports/figures/exploration_MIT/heatmap_corr_age_sexe_label.png
　　　　　　-----> reports/figures/exploration_MIT/signal_moyen_<classe>.png (une par classe)
　　　　　　-----> reports/figures/exploration_MIT/signal_moyen_toutes_classes.png
　　　　　　-----> reports/figures/exploration_MIT/nb_battements_par_type_et_patient.png
　　　　　　-----> reports/figures/exploration_MIT/age_vs_bpm_scatter.png
　　　　　　-----> reports/figures/exploration_MIT/age_box.png
　　　　　　-----> reports/figures/exploration_MIT/age_hist.png
　　　　　　-----> reports/figures/exploration_MIT/sexe_bar.png
　　　　　　-----> reports/figures/exploration_MIT/leads_bar.png


Etape 3 :  Undersampling_strategies_mlii.py ----> Différentes techniques d'undersampling

	Résumé: Ce script prend le fichier mitbih_187pts_fullmeta.csv. Il compare différentes stratégies d'undersampling (proportionnel, équilibré sur minoritaire, 	seulement sur le N, classification par bin, classification AAMI 3-classes et classification binaire) qu'il applique sur un XGBoost basique, et affiche en 	sortie les résultats et les matrices de confusion de chaque stratégie.

--Lance-----------> python src/features/Undersampling_strategies_mlii.py
--On obtient ----->	-- On obtient ----->reports/figures/Preprocess_MIT/cm_under_prop_mlii_counts.png
										reports/figures/Preprocess_MIT/cm_under_prop_mlii_norm.png
										reports/figures/Preprocess_MIT/report_under_prop_mlii.png

										reports/figures/Preprocess_MIT/cm_under_bal_mlii_counts.png
										reports/figures/Preprocess_MIT/cm_under_bal_mlii_norm.png
										reports/figures/Preprocess_MIT/report_under_bal_mlii.png

										reports/figures/Preprocess_MIT/cm_underN_mlii_counts.png
										reports/figures/Preprocess_MIT/cm_underN_mlii_norm.png
										reports/figures/Preprocess_MIT/report_underN_mlii.png

										reports/figures/Preprocess_MIT/cm_aami_mlii_counts.png
										reports/figures/Preprocess_MIT/cm_aami_mlii_norm.png
										reports/figures/Preprocess_MIT/report_aami_mlii.png

										reports/figures/Preprocess_MIT/cm_binary_mlii_counts.png
										reports/figures/Preprocess_MIT/cm_binary_mlii_norm.png
										reports/figures/Preprocess_MIT/report_binary_mlii.png




Etape 4 :  split_mit_MLII_patient_level_20_80.py ----> Création de la base d'entrainement et de test

	Résumé:Ce script prend le fichier mitbih_187pts_MLII.csv, fait un split au niveau patient : 
	~80 % des patients en train, 20 % en test, en s’assurant que toutes les classes 0–4 apparaissent dans le train.
	Ensuite il applique un undersampling sur le train (limite de battements par patient et par label, surtout pour la classe 0) 
	pour réduire le déséquilibre, puis sauvegarde mitbih_187pts_MLII_train_patients.csv et mitbih_187pts_MLII_test_patients.csv.
	
--Lance-----------> python src/features/split_mit_MLII_patient_level_20_80.py
--On obtient ----->	data/processed/mitbih_187pts_MLII_test_patients.csv
			 -----> data/processed/mitbih_187pts_MLII_train_patients.csv


Etape 5 :  src/models/mit_MLII_XGB_binary.py----> Modélisation et optimisation d'un modèle XGBoost

	Résumé: Ce script prend les fichiers data/processed/mitbih_187pts_MLII_train_patients.csv et data/processed/mitbih_187pts_MLII_test_patients.csv en entrée, 	et applique un modèle basique XGBoost, un GridsearchCV, un SMOTE, et enfin un ADASYN, avant d'appliquer un seuil de décision de 0,3. Puis il enregistre le 	meilleur modèle. Il enregistre les reports, matrices de confusion et CV score dans le 	dossier /reports/figures/Modelisation_XGBoost.

--Lance-----------> src/models/mit_MLII_XGB_binary.py
--On obtient ----->	reports/figures/Modelisation_XGBoost/cm_XGB_baseline.png
			reports/figures/Modelisation_XGBoost/report_XGB_baseline.txt

			reports/figures/Modelisation_XGBoost/cm_XGB_gridsearchCV.png
			reports/figures/Modelisation_XGBoost/report_XGB_gridsearchCV.txt
			reports/figures/Modelisation_XGBoost/cv_score_XGB_gridsearchCV.txt

			reports/figures/Modelisation_XGBoost/cm_XGB_SMOTE.png
			reports/figures/Modelisation_XGBoost/report_XGB_SMOTE.txt
			reports/figures/Modelisation_XGBoost/cv_score_XGB_SMOTE.txt

			reports/figures/Modelisation_XGBoost/cm_XGB_adasyn.png
			reports/figures/Modelisation_XGBoost/report_XGB_adasyn.txt
			reports/figures/Modelisation_XGBoost/cv_score_XGB_adasyn.txt
			
Etape 6 :  src/models/mit_MLII_LogReg_binary.py----> Modélisation et optimisation d'un modèle de régression logistique

	Résumé: Ce script prend les fichiers data/processed/mitbih_187pts_MLII_train_patients.csv et data/processed/mitbih_187pts_MLII_test_patients.csv en entrée, 	et applique un modèle basique de regression logistique, un GridsearchCV sur un LBFGS, un GridsearchCV sur un SAGA, et enfin un dernier sur un ElasticNet, 	avant d'appliquer un seuil de décision de 0,3. Puis il enregistre le meilleur modèle. Il enregistre les reports, matrices de confusion et CV score dans le 	dossier /reports/figures/Modelisation_LogisticRegression

--Lance-----------> src/models/mit_MLII_LogReg_binary.py
--On obtient ----->	reports/figures/Modelisation_LogisticRegression/cm_LogReg_baseline.png
			reports/figures/Modelisation_LogisticRegression/report_LogReg_baseline.txt

			reports/figures/Modelisation_LogisticRegression/cm_LogReg_lbfgs_gridsearchCV.png
			reports/figures/Modelisation_LogisticRegression/report_LogReg_lbfgs_gridsearchCV.txt
			reports/figures/Modelisation_LogisticRegression/cv_score_LogReg_lbfgs_gridsearchCV.txt

			reports/figures/Modelisation_LogisticRegression/cm_LogReg_saga_gridsearchCV.png
			reports/figures/Modelisation_LogisticRegression/report_saga_lbfgs_gridsearchCV.txt
			reports/figures/Modelisation_LogisticRegression/cv_score_saga_lbfgs_gridsearchCV.txt

			reports/figures/Modelisation_LogisticRegression/cm_LogReg_elastic.png
			reports/figures/Modelisation_LogisticRegression/report_elastic.txt
			reports/figures/Modelisation_LogisticRegression/cv_score_elastic.txt

			 
			 
			 
			 
			 
Etape .... :build_ptb_metadata.py--------> Compilation des metadata de la base PTB dans un csv 

	Résumé:Ce script parcourt tous les fichiers .hea de la base PTB, lit les commentaires d’entête WFDB et en extrait des paires « clé : valeur » (age, sex, reason_for_admission, etc.) pour chaque enregistrement.
	Il rassemble tout ça dans un DataFrame pandas, force un ensemble de colonnes dans un ordre donné, puis sauvegarde le CSV propre ptb_metadata_all.cleaned.csv dans data/processed.
	
--Lance-----------> python src/features/build_ptb_metadata.py
--On obtient ----->	data/processed/ptb_metadata_all.cleaned.csv
			 

Etape 5 :  build_ptb_beats_with_labels.py ---> Lecture des enregistrement PTB et création du csv contenant les battements avec leurs label

	Résumé: Ce script parcourt tous les enregistrements PTB (ptb-diagnostic-ecg) : il lit les signaux, se cale sur le lead "ii", les resample à 360 Hz,
	détecte les R-peaks et extrait autour de chaque R une fenêtre de 187 points.
	Il récupère ensuite, via les métadonnées, un healthy_label par couple (patient, record) (1 = healthy control, 0 = autre), 
	le fusionne avec les battements, puis sauvegarde le tout dans ptb_beats_all_with_healthy_label.csv.
	
--Lance-----------> python src/features/build_ptb_beats_with_labels.py
--On obtient ----->	data/processed/ptb_beats_all_with_healthy_label.csv



Etape 6 : apply_xgb_on_ptb_beats_with_label.py ----> Applique le model XGBOOST entrainé sur la base MIT-BIH sur les battements de la base PTB

	Résumé : Ce script charge le modèle XGBoost entraîné sur MIT (xgb_mit_mlii_binary.pkl) et l’applique à tous les battements PTB
	du fichier ptb_beats_all_with_healthy_label.csv.
	Pour chaque battement, il calcule la probabilité d’être malade (xgb_proba_malade), la prédiction binaire (xgb_pred_malade), 
	puis construit les labels ground truth malade/healthy (gt_malade, gt_healthy) et les versions prédictives correspondantes.
	Enfin, il ne garde que les colonnes utiles (patient, record, labels, proba, prédictions) 
	et sauvegarde un CSV minimal ptb_beats_xgb_minimal_labels_only.csv pour faciliter l’analyse des performances du modèle.
	
--Lance-----------> python src/models/apply_xgb_on_ptb_beats_with_label.py
--On obtient ----->	data/processed/ptb_beats_xgb_minimal_labels_only.csv

Etape 7 :	ptb_patients_prediction.py   ----> Pédit si le patient et malade en fonction de l'applications du modèle XGBOOST à PTB

	Résumé : Ce script prend le CSV de battements prédits par XGBoost et l’agrège au niveau patient : 
	pour chaque patient, il compte le nombre total de battements et de battements prédits « malades », 
	puis construit un label patient gt_malade à partir de healthy_label.
	Avec la règle “≥ 1 battement anormal ⇒ patient malade”, il produit un CSV ptb_patients_pred_malade.csv 
	(1 ligne par patient, avec GT et prédictions) et génère une matrice de confusion patients sain/malade, 
	sauvegardée dans images/ptb_patients_confusion_malade_vs_sain.png.
	
--Lance-----------> python src/visualization/ptb_patients_prediction.py
--On obtient ----->	data/processed/ptb_patients_pred_malade.csv 
			------->reports/figures/ptb_patients_confusion_malade_vs_sain.png
